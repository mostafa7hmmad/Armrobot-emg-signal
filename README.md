

# EMG Signal Classification for Hand/Arm Movements
![img](emf.jpg)


## ğŸ” Overview

This project classifies electromyography (EMG) signals to predict arm movements (e.g., **elbow bending**, **hand closing**) using a **CNN-LSTM hybrid deep learning model**. The dataset includes EMG signals from the **biceps**, **triceps**, and **middle** muscles, labeled with six different movement classes.

---

## ğŸ“Š Dataset

* **Source:** `/kaggle/input/emgsen/emg_dataset.csv`
* **Shape:** 11,595 rows Ã— 4 columns
* **Features:**

  * `biceps` (float64)
  * `triceps`, `middle` (int64)
  * `label` (target: object)

### âœ… Data Cleaning

* **Missing values:** 189 in `biceps` â†’ imputed via **KNN (k=5)**
* **Duplicates:** 9,109 removed â†’ final dataset: **2,486 rows**

---

## âš™ï¸ Preprocessing Pipeline

* **Standardization:** `StandardScaler` for zero mean, unit variance
* **Outlier Treatment:**

  * Clipping (1stâ€“99th, then 5thâ€“95th percentiles)
  * `PowerTransformer` (Yeo-Johnson)
* **Label Encoding:** `LabelEncoder` for categorical targets
* **Sequence Creation:** Transformed into **2,476 sequences** of shape **(10 timesteps Ã— 3 features)** for time-series modeling

---

## ğŸ“ˆ Exploratory Data Analysis (EDA)

* **Boxplots:** Before/after standardization for outlier visualization
* **Scatter Plots:** Feature vs. label analysis
* **Correlation:** Weak linear correlation with target (`biceps: -0.057`, etc.) â†’ complex models needed

---

## ğŸ§  Model Architecture

A **hybrid CNN-LSTM** model implemented with TensorFlow/Keras:

```
Input: (10, 3)
â†’ Conv1D (64 filters, kernel=3, ReLU)
â†’ MaxPooling1D (pool=2)
â†’ Dropout(0.3)
â†’ LSTM (128, return_sequences=True)
â†’ Dropout(0.5)
â†’ LSTM (64)
â†’ Dropout(0.3)
â†’ BatchNormalization
â†’ Dense (64, ReLU)
â†’ Dropout(0.3)
â†’ Dense (6, softmax)
```

* **Optimizer:** Adam (lr=0.0005, clipnorm=1.0)
* **Loss:** Categorical cross-entropy
* **Metric:** Accuracy

---

## ğŸ‹ï¸â€â™‚ï¸ Training Configuration

* **Data Split:** 80% train / 20% test (with stratification)
* **Epochs:** 300 (early stopping at 97% val accuracy)
* **Batch Size:** 32
* **Callback:** Custom early stop at 97% validation accuracy

### ğŸ Results

* Stopped at **epoch 250**
* **Validation Accuracy:** 97.98%
* **Validation Loss:** 0.0766
* **Training Accuracy:** \~93.24%

---

## ğŸ“Š Visualizations

* Accuracy and loss plots showed **steady learning** and **convergence**
* Validation metrics outperformed training, indicating good generalization

---

## ğŸ“‚ Outputs

* **Preprocessed Data:** `preprosesseddata.csv`
* **Trained Model:** `model.h5`










